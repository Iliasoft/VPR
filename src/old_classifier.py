import numpy as np
import os
import pickle
import torch
from tqdm import tqdm
from configs import config1, config2, config3, config4, config5, config6, config7
from torch.nn import CosineSimilarity
from embeddings_multi_dir import Dict2Class
import sys
from embeddings_multi_dir import get_embedding_file_name, IMAGES_METADATA_FILE_NAME
import shutil
from files import flatten, join, get_dir_name, flatten
import time
import pandas as pd


'''
if __name__ == '__main__':
    
    with open('e:/ebay/VPR/directories.pkl ', 'rb') as f:
        d1 = pickle.load(f)["dirs"]

    with open('e:/ebay/VPRII/directories.pkl ', 'rb') as f:
        d2 = pickle.load(f)["dirs"]

    d = d1 + d2
    with open('e:/ebay/VPRII/directories3.pkl', 'wb') as f:
        pickle.dump({"dirs": d, "last":0}, f)

    groups_df = pd.DataFrame(data=d)
    groups_df.to_csv(
        "e:/ebay/VPRII/directories3.csv",
        header=False, index=True
    )
'''
# -*- coding: utf-8 -*-
"""Train Classificator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WJG1VbBS0LuPJxWLFPHPrXHnc8qMKOow
"""

# Commented out IPython magic to ensure Python compatibility.
# Собрал все imports и иницализацию
import numpy as np
import json
from PIL import Image
import os
from os import listdir
import copy
import random
from torch.nn.utils.rnn import pad_sequence  # pad batch
from torch.utils.data import DataLoader, Dataset
import torch.optim as optim
import torchvision.transforms as transforms
from sklearn.preprocessing import LabelEncoder
import torch, torch.nn as nn
import torch.nn.functional as F
import torch.optim.lr_scheduler as shedulers
import math
from tqdm.notebook import tqdm
from skimage.transform import resize
from skimage import data
from sklearn.metrics import confusion_matrix

from matplotlib import colors, pyplot as plt

# %matplotlib inline

torch.backends.cudnn.benchmark = True
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")


TRAIN_DS_PATH = 'z:/PostcardsClassification/'
GROUND_TRUTH_DS_PATH = "Z:/ebay.us/parsingTest24/"
IMAGE_FEATURES_SIZE = 2048
BATCH_SIZE = 64

# мы будем игнорировать warnings
import warnings

warnings.filterwarnings(action='ignore', category=DeprecationWarning)


class PostcardEmbeddingsDS(Dataset):
    # получить папку датасета, где лежат npy файлы с ранее расчитанными эмбеддингами
    # считать с диска список подпапок, в которых есть NPY файл
    # трактовать полученный список подпапок как классы
    # считать в память все npy файлы
    # как разделить датасеты так, чтобы сохранить пропорции классов???
    classes = [
        "GoodPostcards",
        "Animals",
        "ArtPostcards",
        "Badges",
        "Books",
        "Bottles",
        "Clothes",
        "Coins",
        "ComicPostcards",
        "Documents",
        "Faces",
        "Fingers",
        "Flowers",
        "ForeignObjects",
        "Greetings",
        "Holidays",
        "Kitchenware",
        "MapPostcards",
        "MatchBooks",
        "MultiplePostcards",
        "Newspapers",
        "PatrioticPostcards",
        "PCKeyboards",
        "Pennants",
        "PlayingCards",
        "Pottery",
        "RadioCards",
        # "ReverseSides",
        # "Scrapbooks",
        "SportPostcards",
        "Stationary",
        "WrappingPapers"
    ]

    def __init__(self, root_dir):
        self.root_dir = root_dir
        self.labels = []
        self.classes_startPositions = []
        self.imgFeatures = np.empty(shape=[0, IMAGE_FEATURES_SIZE], dtype=np.float32)
        # Finding embedding files
        for classes_dir in PostcardEmbeddingsDS.classes:

            if (os.path.exists(os.path.join(root_dir + classes_dir, "image features.npy"))):
                loadedFeatures = np.load(os.path.join(root_dir + classes_dir, "image features.npy"))
                print(loadedFeatures.shape[0], " @ ", classes_dir)
                self.labels.append(classes_dir)

                self.classes_startPositions.append(self.imgFeatures.shape[0])
                self.imgFeatures = np.append(self.imgFeatures, loadedFeatures, axis=0)

        # print(self.classes_startPositions)

        print(self.labels)
        print("Classes Number: %d" % len(self.labels))

    def __len__(self):
        return len(self.imgFeatures)

    def __getitem__(self, index):
        # определим класс изображения
        # нужно найти номер элемента в self.classes_startPositions
        # у которого значение меньше чем i <= index < i+1
        classId = len(self.classes_startPositions) - 1
        for i in range(len(self.classes_startPositions)):
            if i == len(self.classes_startPositions) - 1:
                break

            if self.classes_startPositions[i] <= index and index < self.classes_startPositions[i + 1]:
                classId = i
                break

        return self.imgFeatures[index], classId, ""

    def getClassesNumber(self):
        return len(self.labels)

    def getClassLabel(self, classId):
        return self.labels[classId]

    @staticmethod
    def prepareDataSets(
            root_folder,
            trainValidationRatio=0.8,
            batch_size=BATCH_SIZE,
            num_workers=0,
            pin_memory=True):
        # если передать entireDataset.vocab, то можно будет объединить словари двух датасетов и тренировать модель на двух датасетах сразу
        dataset = PostcardEmbeddingsDS(root_folder)

        ###############
        train_size = int(trainValidationRatio * len(dataset))
        validation_size = len(dataset) - train_size
        train_dataset, validation_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size])
        ###############

        trainLoader = DataLoader(
            dataset=train_dataset,
            batch_size=batch_size,
            num_workers=num_workers,
            shuffle=False,
            pin_memory=pin_memory,
            collate_fn=None
        )

        if validation_size > 0:
            validationLoader = DataLoader(
                dataset=validation_dataset,
                batch_size=batch_size,
                num_workers=num_workers,
                shuffle=False,
                pin_memory=pin_memory,
                collate_fn=None
            )
        else:
            validationLoader = None
            validation_dataset = None

        return dataset, trainLoader, train_dataset, validationLoader, validation_dataset


class GroundTruthDS(Dataset):
    # получить корневую папку датасета
    # считать именя файлов с диска из заранее определнных подпапок
    # трактовать список подпапок как классы и нахождение в них файлов как принадлежность к классу
    # считать единственный npy файл и использовать его для получения IF
    #
    # связь между дисковым файлом и IF осуществлять по именя файла без учета поного пути
    bad_classes = list([
        "goods",
        "bads_backs",
        "bads_exibition_animals",
        "bads_flowers_n_greetings",
        "bads_foreign_objects",
        "bads_maps",
        "bads_multiple_cards",
        "bads_non_cards",
        "bads_non_card_papers",
        "bads_pennants",
        "bads_radio_cards",
        "bad_portrait",
        "other_undesired_cards"
    ])
    # одному классу Ground truth соответствуют несколько классов из обучающего набора
    # Одному классу из тестового набора соответствует один класс из GroundTruth набора
    train_labels_mapping = {
        # нет смысла менять ноль на ноль, потому закоментарил маппинг по категориям Хорошие
        PostcardEmbeddingsDS.classes.index("GoodPostcards"): bad_classes.index("goods"),
        PostcardEmbeddingsDS.classes.index("Animals"): bad_classes.index("bads_exibition_animals"),
        PostcardEmbeddingsDS.classes.index("ArtPostcards"): bad_classes.index("other_undesired_cards"),
        PostcardEmbeddingsDS.classes.index("Badges"): bad_classes.index("bads_non_cards"),
        PostcardEmbeddingsDS.classes.index("Books"): bad_classes.index("bads_non_card_papers"),
        PostcardEmbeddingsDS.classes.index("Bottles"): bad_classes.index("bads_non_cards"),
        PostcardEmbeddingsDS.classes.index("Clothes"): bad_classes.index("bads_non_cards"),
        PostcardEmbeddingsDS.classes.index("Coins"): bad_classes.index("bads_non_cards"),
        PostcardEmbeddingsDS.classes.index("ComicPostcards"): bad_classes.index("other_undesired_cards"),
        PostcardEmbeddingsDS.classes.index("Documents"): bad_classes.index("bads_non_card_papers"),
        PostcardEmbeddingsDS.classes.index("Faces"): bad_classes.index("bad_portrait"),
        PostcardEmbeddingsDS.classes.index("Fingers"): bad_classes.index("bads_foreign_objects"),
        PostcardEmbeddingsDS.classes.index("Flowers"): bad_classes.index("bads_flowers_n_greetings"),
        PostcardEmbeddingsDS.classes.index("ForeignObjects"): bad_classes.index("bads_foreign_objects"),
        PostcardEmbeddingsDS.classes.index("Greetings"): bad_classes.index("bads_flowers_n_greetings"),
        PostcardEmbeddingsDS.classes.index("Holidays"): bad_classes.index("bads_flowers_n_greetings"),
        PostcardEmbeddingsDS.classes.index("Kitchenware"): bad_classes.index("bads_non_cards"),
        PostcardEmbeddingsDS.classes.index("MapPostcards"): bad_classes.index("bads_maps"),
        PostcardEmbeddingsDS.classes.index("MatchBooks"): bad_classes.index("bads_non_card_papers"),
        PostcardEmbeddingsDS.classes.index("MultiplePostcards"): bad_classes.index("bads_multiple_cards"),
        PostcardEmbeddingsDS.classes.index("Newspapers"): bad_classes.index("bads_non_card_papers"),
        PostcardEmbeddingsDS.classes.index("PatrioticPostcards"): bad_classes.index("other_undesired_cards"),
        PostcardEmbeddingsDS.classes.index("PCKeyboards"): bad_classes.index("bads_foreign_objects"),
        PostcardEmbeddingsDS.classes.index("Pennants"): bad_classes.index("bads_pennants"),
        PostcardEmbeddingsDS.classes.index("PlayingCards"): bad_classes.index("bads_non_card_papers"),
        PostcardEmbeddingsDS.classes.index("Pottery"): bad_classes.index("bads_non_cards"),
        PostcardEmbeddingsDS.classes.index("RadioCards"): bad_classes.index("bads_radio_cards"),
        # PostcardEmbeddingsDS.classes.index("ReverseSides"):bad_classes.index("bads_backs"),
        # PostcardEmbeddingsDS.classes.index("Scrapbooks"):bad_classes.index("bads_non_card_papers"),
        PostcardEmbeddingsDS.classes.index("SportPostcards"): bad_classes.index("other_undesired_cards"),
        PostcardEmbeddingsDS.classes.index("Stationary"): bad_classes.index("bads_non_card_papers"),
        PostcardEmbeddingsDS.classes.index("WrappingPapers"): bad_classes.index("bads_non_card_papers"),
    }

    @staticmethod
    def translateToLabels(trainDSLabels):

        # print(map(lambda x:GroundTruthDS.train_labels_mapping[x], trainDSLabels))
        return list(map(lambda x: GroundTruthDS.train_labels_mapping[x], trainDSLabels))

    @staticmethod
    def translateToBinaryLabels(trainDSLabels):

        # print(map(lambda x:GroundTruthDS.train_labels_mapping[x], trainDSLabels))
        return list(map(lambda x: 0 if x == 0 else 1, trainDSLabels))

    def __init__(self, root_dir=GROUND_TRUTH_DS_PATH):
        # папки с плохими картинками плохих классов

        self.root_dir = root_dir
        self.imgFeatures = []
        self.sortedFileNames = []
        # загружаем ранее сформированный список файлов, отсортированный так же как и image Features

        if (os.path.exists(os.path.join(root_dir, "image features.npy"))):

            self.sortedFileNames = list(np.load(os.path.join(root_dir, "list of images.npy")))
            print(len(self.sortedFileNames), "image names in the DS")
        else:
            print("!!!  Image names are not in the DS !!! ")

        # загружаем ранее сформированные ImageFeatures
        if (os.path.exists(os.path.join(root_dir, "image features.npy"))):

            # loadedFeatures = np.load(os.path.join(root_dir,"image features.npy"))
            # self.imgFeatures = np.append(self.imgFeatures, loadedFeatures,axis=0)
            self.imgFeatures = np.load(os.path.join(root_dir, "image features.npy"))

            print(len(self.imgFeatures), "image features in the DS")
        else:
            print("!!!  Image features are not in the DS !!! ")

        # формируем общий список изображений - названия фаqлов, без файловой структуры
        self.imgs = []
        for root, dirs, files in os.walk(root_dir):
            for file in files:
                if (file.endswith(".png") or file.endswith(".jpg")):
                    self.imgs.append(file)

        print("%d image files in the DS" % len(self.imgs))
        # формируем принадлежность изображений к классам

        self.img2Class = {}
        # формируем список файлов, входящих в плохие категории
        # изображения хорошего класса в selfimg2Class Добавлять не будем, чтобы экономить память
        for bad_class_ids in range(1, len(GroundTruthDS.bad_classes)):
            for root, dirs, files in os.walk(root_dir + "/" + GroundTruthDS.bad_classes[bad_class_ids]):
                # print(bad_class_ids, " -> ", len(files))
                for file in files:
                    if (file.endswith(".png") or file.endswith(".jpg")):
                        self.img2Class[file] = bad_class_ids

    def __len__(self):

        if (len(self.imgs) != len(self.imgFeatures)): print('images number != features number')

        return len(self.imgs)

    def __getitem__(self, index):
        # находим по index имя диского файла
        # находим по имени файла image Feature
        # ищем имя файла в категории плохих
        # класс изображения либо категория плохих где он найден, либо хороший (-1)

        imgFeatures = None
        fileName = self.imgs[index]

        # всегда должно быть имя файла в npy-списке файлов, иначе не будет расчитанных ImageFeatures
        # вынес это их под try/catch
        ifIndex = self.sortedFileNames.index(fileName)
        imgFeatures = self.imgFeatures[ifIndex]
        # print(ifIndex)

        # поищем его среди плохих категорий
        classIndex = 0  # good
        try:
            classIndex = self.img2Class[fileName]
        except:
            pass
        return imgFeatures, classIndex, fileName

    def getClassesNumber(self):
        return len(self.bad_classes)

    def getClassLabel(self, classId):
        return self.bad_classes[classId]

    def getItemPath(self, index):
        # находим по index имя диского файла
        # ищем имя файла в категории плохих
        # класс изображения либо категория плохих где он найден, либо хороший (-1)

        fileName = self.imgs[index]

        # всегда должно быть имя файла в npy-списке файлов, иначе не будет расчитанных ImageFeatures
        # вынес это их под try/catch
        ifIndex = self.sortedFileNames.index(fileName)

        # поищем его среди плохих категорий
        classIndex = 0  # good
        try:
            classIndex = self.img2Class[fileName]
        except:
            pass
        return self.root_dir + self.bad_classes[classIndex] + '\\' + fileName


def fit_epoch(model, train_loader, criterion, optimizer):
    model.train()
    running_loss = 0.0
    running_corrects = 0
    processed_data = 0

    for inputs, labels, _ in train_loader:
        # print(inputs[0])
        inputs = inputs.to(DEVICE)
        labels = labels.to(DEVICE)
        optimizer.zero_grad()

        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        preds = torch.argmax(outputs, 1)
        running_loss += loss.item() * inputs.size(0)
        running_corrects += torch.sum(preds == labels.data)
        processed_data += inputs.size(0)

    train_loss = running_loss / processed_data
    train_acc = running_corrects.cpu().numpy() / processed_data
    return train_loss, train_acc


from sklearn.metrics import f1_score, recall_score, precision_score


def eval_epoch(model, val_loader, criterion, labelsTranslator=None):
    model.eval()
    running_loss = 0.0
    running_corrects = 0
    processed_size = 0

    allTrueLabels = np.array([], dtype='int16')
    allPreds = np.array([], dtype='int16')
    allImgIds = []

    for inputs, labels, imgIds in val_loader:
        inputs = inputs.to(DEVICE)
        labels = labels.to(DEVICE)

        with torch.set_grad_enabled(False):
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            preds = torch.argmax(outputs, 1)
        # if processed_size == 0:
        #    print(">>> ", outputs[0], torch.argmax(outputs[0]), labels[0], imgIds[0])

        running_loss += loss.item() * inputs.size(0)
        running_corrects += torch.sum(preds == labels.data)
        processed_size += inputs.size(0)

        allTrueLabels = np.append(allTrueLabels, labels.data.numpy().astype('int16'))
        allPreds = np.append(allPreds, preds.numpy().astype('int16'))

        if labelsTranslator is not None:
            allImgIds = np.append(allImgIds, imgIds)

    val_loss = running_loss / processed_size
    val_acc = running_corrects.cpu().numpy() / processed_size

    allBinaryPreds = GroundTruthDS.translateToBinaryLabels(allPreds)
    allBinaryLabels = GroundTruthDS.translateToBinaryLabels(allTrueLabels)

    f1b = f1_score(allBinaryLabels, allBinaryPreds, average='binary', pos_label=0)

    if labelsTranslator is None:

        return val_loss, val_acc, confusion_matrix(allTrueLabels, allPreds), f1b
    else:
        allPreds = GroundTruthDS.translateToLabels(allPreds)
        print('F1 Multiclass %.3f' % f1_score(allTrueLabels, allPreds, average='micro'))
        print('F1 Binary %.3f' % f1b)

        # printMisidentifiedImages(groundTruthDS, allTrueLabels, allPreds, allImgIds,0)
        return val_loss, val_acc, confusion_matrix(allTrueLabels, allPreds), f1b


def train(train_loader, val_loader, model, epochs, batch_size):
    # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    # val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    bestAccuracy = 0
    bestLoss = np.inf
    bestF1 = 0

    history = []
    log_template = "\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \
    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}"

    with tqdm(desc="epoch", total=epochs) as pbar_outer:

        # IE: поменял оптимизаотор. Включение флага amsgrad резултат не улучшило
        opt = torch.optim.AdamW(model.parameters(), lr=0.0001, amsgrad=True)

        criterion = nn.CrossEntropyLoss()
        # IE: Добавил управление LR
        scheduler = shedulers.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=2, min_lr=0.0000001)
        #
        for epoch in range(epochs):
            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)
            # IE: Добавил, чтобы отображать текущий LR
            """
            if epoch != 0:
                print("loss", train_loss, ' LR:', scheduler._last_lr)
            else:
                print("loss", train_loss)
            """
            val_loss, val_acc, confusionMatrix, f1 = eval_epoch(model, val_loader, criterion)
            if val_acc > bestAccuracy:
                bestAccuracy = val_acc
                bestConfusionMatrix = confusionMatrix

            if val_loss < bestLoss:
                bestLoss = val_loss

            if f1 > bestF1:
                bestF1 = f1
                bestModelWeights = copy.deepcopy(model.state_dict())
            history.append((train_loss, train_acc, val_loss, val_acc))

            pbar_outer.update(1)
            # tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss, v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))

            # IE: добавил, чтобы правильно работал скедюлер ReduceLROnPlateau
            scheduler.step(val_loss)
    return history, bestAccuracy, bestLoss, bestConfusionMatrix, bestModelWeights


# IE: Самодельная модель
class PostcardsClassifier(nn.Module):

    def __init__(self, n_classes):

        super().__init__()
        self.n_classes = n_classes
        self.linear = nn.Linear(IMAGE_FEATURES_SIZE, int(IMAGE_FEATURES_SIZE / 2))
        self.linear2 = nn.Linear(int(IMAGE_FEATURES_SIZE / 2), self.n_classes)

        self.classifier1 = nn.Sequential(
            self.linear,
            nn.Dropout(p=0.2),
            nn.Sigmoid(),
            self.linear2,
            nn.Dropout(p=0.2),
        )
        self.classifier2 = nn.Sequential(
            self.linear,
            nn.Sigmoid(),
            self.linear2,
        )

        self.linear.weight.data.uniform_(-0.1, 0.1)
        self.linear.bias.data.fill_(0)
        self.linear2.weight.data.uniform_(-0.1, 0.1)
        self.linear2.bias.data.fill_(0)

        model_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        print("Model parameters: %d" % (model_params))

    def forward(self, x):
        # print("1", x.shape)
        if self.training:
            preds = self.classifier1(x)
        else:
            preds = self.classifier2(x)
        # print("2", preds.shape)
        return preds


ds, trainLoader, trainDS, testLoader, testDS = PostcardEmbeddingsDS.prepareDataSets(TRAIN_DS_PATH,
                                                                                    trainValidationRatio=0.95)
print("Datasets lengths %d,%d,%d" % (len(ds), len(trainDS), len(testDS)))


# функция выводит на печать Confusion Matrix в виде
# Название класса, и в упорядоченном порядке неверное распознанные классы, превышающие заданный порог в %

def printConfusionMatrix(cm, ds, threshHold=3):
    for clsID in range(len(cm[0])):

        confusionMSG = ds.getClassLabel(clsID) + "[%.1f] " % (100 * cm[clsID][clsID] / np.sum(cm[clsID]))
        sortedConfusions = cm[clsID].argsort()[::-1]
        # print(sortedConfusions)
        for confusedClass in sortedConfusions:
            confusedPercentage = 100 * cm[clsID][confusedClass] / np.sum(cm[clsID])
            # print(confusedPercentage)
            if confusedClass != clsID and confusedPercentage > threshHold:
                confusionMSG += ds.getClassLabel(confusedClass) + " " + "%.1f:" % (confusedPercentage)
        print(confusionMSG)


model = PostcardsClassifier(ds.getClassesNumber())
history, bestAccuracy, bestLoss, confusionMatrix, bestModelWeights = train(trainLoader, testLoader, model=model,
                                                                           epochs=25, batch_size=BATCH_SIZE)

print("Best Acc %.3f Loss %.3f " % (bestAccuracy, bestLoss))

printConfusionMatrix(confusionMatrix, ds)
"""
loss, acc, val_loss, val_acc = zip(*history)
plt.figure(figsize=(15, 9))
plt.plot(acc, label="train_acc")
plt.plot(val_acc, label="val_acc")
plt.legend(loc='best')
plt.xlabel("epochs")
plt.ylabel("acc")
plt.show()

plt.figure(figsize=(15, 9))
plt.plot(loss, label="train_loss")
plt.plot(val_loss, label="val_loss")
plt.legend(loc='best')
plt.xlabel("epochs")
plt.ylabel("loss")
plt.show()
"""
# сохранить веса нашей нейросети model
torch.save(bestModelWeights, TRAIN_DS_PATH + 'classifier.pth')

loss, acc, val_loss, val_acc = zip(*history)
plt.figure(figsize=(15, 9))
plt.plot(acc, label="train_acc")
plt.plot(val_acc, label="val_acc")
plt.legend(loc='best')
plt.xlabel("epochs")
plt.ylabel("acc")
plt.show()

plt.figure(figsize=(15, 9))
plt.plot(loss, label="train_loss")
plt.plot(val_loss, label="val_loss")
plt.legend(loc='best')
plt.xlabel("epochs")
plt.ylabel("loss")
plt.show()

model = PostcardsClassifier(ds.getClassesNumber())
model.load_state_dict(torch.load(TRAIN_DS_PATH + 'classifier.pth'))


# получить имена файлов по которым распознание произошло неверно
# GT категория - Good
# ограничить вывод первыми n изображениями

# на вход
# confusion matrix
# список image Ids
# датасет
# id категории
# n

def printMisidentifiedImages(ds, allTrueLabels, allPreds, imgIds, categoryId=0, n=100):
    # print(allTrueLabels[0], allPreds[0], imgIds[0])
    indexes = (allTrueLabels != allPreds)  # (allTrueLabels == categoryId) and
    nn = 0
    for idx in range(len(indexes)):

        if indexes[idx] and (allTrueLabels[idx] == categoryId):
            print(ds.getItemPath(idx), ds.getClassLabel(allPreds[idx]))
            nn += 1
        if nn > n: break


groundTruthDS = GroundTruthDS()
groundTruthLoader = DataLoader(dataset=groundTruthDS, batch_size=BATCH_SIZE, num_workers=0, shuffle=False,
                               pin_memory=True, collate_fn=None)

bestLoss, bestAccuracy, confusionMatrix, bestf1 = eval_epoch(model, groundTruthLoader, nn.CrossEntropyLoss(),
                                                             GroundTruthDS.translateToLabels)

print("F1 %.3f, Acc %.3f Loss %.3f " % (bestf1, bestAccuracy, bestLoss))
printConfusionMatrix(confusionMatrix, groundTruthDS)

print("F1 %.3f, Acc %.3f Loss %.3f " % (bestf1, bestAccuracy, bestLoss))
printConfusionMatrix(confusionMatrix, groundTruthDS)

